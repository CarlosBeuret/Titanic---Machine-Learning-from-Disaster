{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=center>Proyecto: Titanic - Machine Learning from Disaster</h1>\n",
    "<hr>\n",
    "<h2 align=center>Probamos modelos de ML</h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importamos librerias.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler, LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "import pickle\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=center>1.-Realizamos la lectura de los datos y los guardamos en sus respectivos dataframes.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(\"../datasets/test.csv\")\n",
    "data_train = pd.read_csv(\"../datasets/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"le = LabelEncoder()\\nle.fit(data_train['Cabin'])\\ndata_train['Cabin']= le.transform(data_train['Cabin'])\""
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_train[\"Age\"].fillna(data_train[\"Age\"].median(),inplace=True)\n",
    "#data_test[\"Age\"].fillna(data_test[\"Age\"].median(),inplace=True)\n",
    "\n",
    "data_test[\"Fare\"].fillna(data_test[\"Fare\"].median(),inplace=True)\n",
    "\"\"\"le = LabelEncoder()\n",
    "le.fit(data_train['Cabin'])\n",
    "data_train['Cabin']= le.transform(data_train['Cabin'])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Vemos la posilibilad de establecer la edad en rangos.\n",
    "bins= [0,10,20,30,40,50,60,100]\n",
    "names = ['0','1','2','3','4','5','6']\n",
    "data_train['Age'] = pd.cut(data_train['Age'], bins, labels=names)\n",
    "data_test['Age'] = pd.cut(data_test['Age'], bins, labels=names)\n",
    "data_train = pd.concat([data_train ,pd.get_dummies(data_train['Age'])], axis=1 )\n",
    "data_test = pd.concat([data_test ,pd.get_dummies(data_test['Age'])], axis=1 )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=center>2.-Realizamos pipelines.</h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos el modelo a utilizar. Para cambiar el modelo solo basta con cambiarlo en la siguiente linea de código sin que sea necesario alterar pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = DecisionTreeClassifier(criterion= 'gini', max_depth= 8,min_samples_leaf= 1, min_samples_split= 1)\n",
    "#model = KNeighborsClassifier(algorithm='auto', leaf_size=10, n_neighbors=9)\n",
    "#model = BaggingClassifier()\n",
    "#model = RandomForestClassifier(criterion='gini', max_depth=6, min_samples_split=6, n_estimators=110,min_samples_leaf=1)#\n",
    "model = RandomForestClassifier()\n",
    "#model = SVC(C= 10, gamma= 0.1, kernel= 'rbf')\n",
    "#model = xgb.XGBClassifier()\n",
    "#model = xgb.XGBClassifier(colsample_bytree= 0.8,gamma= 1, max_depth= 3, min_child_weight= 1, subsample= 1.0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos el set de entrenamiento y testeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= data_train[['Pclass', 'Sex', 'Fare','Embarked','0','SibSp']]\n",
    "y= data_train['Survived']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=60, stratify=y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos por medio de variables que procesos de transformacion se le aplicaran a las diversas columnas. Para cambiar, solo basta con modificar el contenido de las variables sin que sea necesario alterar pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal =['Sex','Embarked','0' ]\n",
    "ordinal =['Pclass' ]\n",
    "numerical = ['Fare','SibSp']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos pipeline relativos a la tranformación  de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline datos numéricos.\n",
    "numerical_pipeline = Pipeline([('escaler', StandardScaler())])\n",
    "#Pipeline datos ordinales. \n",
    "ordinal_pipeline = Pipeline([(\"encoder\", OrdinalEncoder())])\n",
    "#Pipeline datos nominales.\n",
    "nominal_pipeline = Pipeline([(\"encoder2\", OneHotEncoder())])\n",
    "\n",
    "#Unimos los dos procesos en un mismo Pipeline.\n",
    "preprocessin_pipeline = ColumnTransformer([(\"ordinal_preprocesor\", ordinal_pipeline, ordinal),\n",
    "                                            (\"nominal_preprocessor\", nominal_pipeline, nominal),\n",
    "                                            (\"numerical_preprocessor\",numerical_pipeline, numerical) ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos el pipeline completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_pipeline= Pipeline ([(\"preprocessor\", preprocessin_pipeline), (\"estimator\", model)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=center>3.-Probamos los modelos.</h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A.-Utilizamos GridSearch para orientarnos con la elección de hiperparametros.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_xgb = {'estimator__n_estimators':range(20,220,10),\n",
    "        'estimator__seed':range(4, 60, 4),\n",
    "        'estimator__min_child_weight': [1, 5, 10],\n",
    "        'estimator__gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'estimator__subsample': [0.6, 0.8, 1.0],\n",
    "        'estimator__colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'estimator__max_depth': [3, 4, 5]\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametros DecisionTreeClassifier\n",
    "\n",
    "params_tree = {\n",
    "             'estimator__criterion' : ['gini', 'entropy'],\n",
    "             'estimator__min_samples_split':range(1,10),\n",
    "             'estimator__min_samples_leaf':range(1,10),\n",
    "             'estimator__max_depth':range(1,20) \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params_RandomTree = {\n",
    "             'estimator__criterion' : ['gini', 'entropy'],\n",
    "             'estimator__n_estimators': range(20,220,10),\n",
    "             'estimator__min_samples_split':range(1,10),\n",
    "             'estimator__min_samples_leaf':range(1,10),\n",
    "             'estimator__max_depth':range(1,20) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[39m=\u001b[39m GridSearchCV(complete_pipeline, param_grid\u001b[39m=\u001b[39mparams_RandomTree, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\u001b[39m#, scoring = ['accuracy', 'recall'], refit = 'accuracy' )\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[1;32mc:\\Users\\guill\\OneDrive\\Documentos\\Proyectos de data\\ML-1\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\guill\\OneDrive\\Documentos\\Proyectos de data\\ML-1\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1389\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1387\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1388\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1389\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\guill\\OneDrive\\Documentos\\Proyectos de data\\ML-1\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    819\u001b[0m         )\n\u001b[0;32m    820\u001b[0m     )\n\u001b[1;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    824\u001b[0m         clone(base_estimator),\n\u001b[0;32m    825\u001b[0m         X,\n\u001b[0;32m    826\u001b[0m         y,\n\u001b[0;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    833\u001b[0m     )\n\u001b[0;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    836\u001b[0m     )\n\u001b[0;32m    837\u001b[0m )\n\u001b[0;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\guill\\OneDrive\\Documentos\\Proyectos de data\\ML-1\\venv\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\guill\\OneDrive\\Documentos\\Proyectos de data\\ML-1\\venv\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\guill\\OneDrive\\Documentos\\Proyectos de data\\ML-1\\venv\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\guill\\OneDrive\\Documentos\\Proyectos de data\\ML-1\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\guill\\OneDrive\\Documentos\\Proyectos de data\\ML-1\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\guill\\OneDrive\\Documentos\\Proyectos de data\\ML-1\\venv\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\guill\\OneDrive\\Documentos\\Proyectos de data\\ML-1\\venv\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\guill\\OneDrive\\Documentos\\Proyectos de data\\ML-1\\venv\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\guill\\OneDrive\\Documentos\\Proyectos de data\\ML-1\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\guill\\OneDrive\\Documentos\\Proyectos de data\\ML-1\\venv\\lib\\site-packages\\sklearn\\pipeline.py:406\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    405\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m--> 406\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\u001b[39m.\u001b[39mfit(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    408\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\guill\\OneDrive\\Documentos\\Proyectos de data\\ML-1\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:474\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    463\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    464\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    465\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    466\u001b[0m ]\n\u001b[0;32m    468\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 474\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    475\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    476\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    477\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    478\u001b[0m )(\n\u001b[0;32m    479\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    480\u001b[0m         t,\n\u001b[0;32m    481\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    482\u001b[0m         X,\n\u001b[0;32m    483\u001b[0m         y,\n\u001b[0;32m    484\u001b[0m         sample_weight,\n\u001b[0;32m    485\u001b[0m         i,\n\u001b[0;32m    486\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    487\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    488\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    489\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    490\u001b[0m     )\n\u001b[0;32m    491\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    492\u001b[0m )\n\u001b[0;32m    494\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    495\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\guill\\OneDrive\\Documentos\\Proyectos de data\\ML-1\\venv\\lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mc:\\Users\\guill\\OneDrive\\Documentos\\Proyectos de data\\ML-1\\venv\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\guill\\OneDrive\\Documentos\\Proyectos de data\\ML-1\\venv\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\guill\\OneDrive\\Documentos\\Proyectos de data\\ML-1\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\guill\\OneDrive\\Documentos\\Proyectos de data\\ML-1\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\guill\\OneDrive\\Documentos\\Proyectos de data\\ML-1\\venv\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\guill\\OneDrive\\Documentos\\Proyectos de data\\ML-1\\venv\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\guill\\OneDrive\\Documentos\\Proyectos de data\\ML-1\\venv\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\guill\\OneDrive\\Documentos\\Proyectos de data\\ML-1\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:172\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     curr_sample_weight \u001b[39m=\u001b[39m sample_weight\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m--> 172\u001b[0m indices \u001b[39m=\u001b[39m _generate_sample_indices(\n\u001b[0;32m    173\u001b[0m     tree\u001b[39m.\u001b[39;49mrandom_state, n_samples, n_samples_bootstrap\n\u001b[0;32m    174\u001b[0m )\n\u001b[0;32m    175\u001b[0m sample_counts \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mbincount(indices, minlength\u001b[39m=\u001b[39mn_samples)\n\u001b[0;32m    176\u001b[0m curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m sample_counts\n",
      "File \u001b[1;32mc:\\Users\\guill\\OneDrive\\Documentos\\Proyectos de data\\ML-1\\venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:129\u001b[0m, in \u001b[0;36m_generate_sample_indices\u001b[1;34m(random_state, n_samples, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[39mPrivate function used to _parallel_build_trees function.\"\"\"\u001b[39;00m\n\u001b[0;32m    128\u001b[0m random_instance \u001b[39m=\u001b[39m check_random_state(random_state)\n\u001b[1;32m--> 129\u001b[0m sample_indices \u001b[39m=\u001b[39m random_instance\u001b[39m.\u001b[39;49mrandint(\u001b[39m0\u001b[39;49m, n_samples, n_samples_bootstrap)\n\u001b[0;32m    131\u001b[0m \u001b[39mreturn\u001b[39;00m sample_indices\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = GridSearchCV(complete_pipeline, param_grid=params_RandomTree, cv=5)#, scoring = ['accuracy', 'recall'], refit = 'accuracy' )\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'estimator__colsample_bytree': 0.8, 'estimator__gamma': 1, 'estimator__max_depth': 3, 'estimator__min_child_weight': 1, 'estimator__subsample': 1.0}\n",
      "Mejor Score: 0.8286910272825766\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_estimator__colsample_bytree</th>\n",
       "      <th>param_estimator__gamma</th>\n",
       "      <th>param_estimator__max_depth</th>\n",
       "      <th>param_estimator__min_child_weight</th>\n",
       "      <th>param_estimator__subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.072960</td>\n",
       "      <td>0.029063</td>\n",
       "      <td>0.011927</td>\n",
       "      <td>0.002440</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'estimator__colsample_bytree': 0.6, 'estimato...</td>\n",
       "      <td>0.790210</td>\n",
       "      <td>0.825175</td>\n",
       "      <td>0.802817</td>\n",
       "      <td>0.823944</td>\n",
       "      <td>0.823944</td>\n",
       "      <td>0.813218</td>\n",
       "      <td>0.014217</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.061137</td>\n",
       "      <td>0.005331</td>\n",
       "      <td>0.008614</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'estimator__colsample_bytree': 0.6, 'estimato...</td>\n",
       "      <td>0.783217</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.795775</td>\n",
       "      <td>0.809859</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.813218</td>\n",
       "      <td>0.022757</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.075342</td>\n",
       "      <td>0.027963</td>\n",
       "      <td>0.014982</td>\n",
       "      <td>0.004318</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'estimator__colsample_bytree': 0.6, 'estimato...</td>\n",
       "      <td>0.783217</td>\n",
       "      <td>0.832168</td>\n",
       "      <td>0.802817</td>\n",
       "      <td>0.823944</td>\n",
       "      <td>0.830986</td>\n",
       "      <td>0.814626</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.133262</td>\n",
       "      <td>0.010979</td>\n",
       "      <td>0.020282</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'estimator__colsample_bytree': 0.6, 'estimato...</td>\n",
       "      <td>0.783217</td>\n",
       "      <td>0.790210</td>\n",
       "      <td>0.795775</td>\n",
       "      <td>0.838028</td>\n",
       "      <td>0.809859</td>\n",
       "      <td>0.803418</td>\n",
       "      <td>0.019392</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.131177</td>\n",
       "      <td>0.019999</td>\n",
       "      <td>0.018459</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'estimator__colsample_bytree': 0.6, 'estimato...</td>\n",
       "      <td>0.776224</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.795775</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.823944</td>\n",
       "      <td>0.810440</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0.077087</td>\n",
       "      <td>0.003097</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'estimator__colsample_bytree': 1.0, 'estimato...</td>\n",
       "      <td>0.776224</td>\n",
       "      <td>0.797203</td>\n",
       "      <td>0.774648</td>\n",
       "      <td>0.830986</td>\n",
       "      <td>0.830986</td>\n",
       "      <td>0.802009</td>\n",
       "      <td>0.024964</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>0.071896</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.011937</td>\n",
       "      <td>0.002542</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'estimator__colsample_bytree': 1.0, 'estimato...</td>\n",
       "      <td>0.783217</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.809859</td>\n",
       "      <td>0.852113</td>\n",
       "      <td>0.830986</td>\n",
       "      <td>0.816074</td>\n",
       "      <td>0.023582</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>0.063945</td>\n",
       "      <td>0.002106</td>\n",
       "      <td>0.009393</td>\n",
       "      <td>0.001385</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'estimator__colsample_bytree': 1.0, 'estimato...</td>\n",
       "      <td>0.776224</td>\n",
       "      <td>0.783217</td>\n",
       "      <td>0.774648</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>0.781690</td>\n",
       "      <td>0.786536</td>\n",
       "      <td>0.015519</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>0.067480</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>0.009203</td>\n",
       "      <td>0.003207</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'estimator__colsample_bytree': 1.0, 'estimato...</td>\n",
       "      <td>0.783217</td>\n",
       "      <td>0.797203</td>\n",
       "      <td>0.802817</td>\n",
       "      <td>0.823944</td>\n",
       "      <td>0.809859</td>\n",
       "      <td>0.803408</td>\n",
       "      <td>0.013490</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>0.069842</td>\n",
       "      <td>0.004061</td>\n",
       "      <td>0.012205</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'estimator__colsample_bytree': 1.0, 'estimato...</td>\n",
       "      <td>0.776224</td>\n",
       "      <td>0.811189</td>\n",
       "      <td>0.795775</td>\n",
       "      <td>0.823944</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>0.804806</td>\n",
       "      <td>0.017040</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>405 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         0.072960      0.029063         0.011927        0.002440   \n",
       "1         0.061137      0.005331         0.008614        0.000823   \n",
       "2         0.075342      0.027963         0.014982        0.004318   \n",
       "3         0.133262      0.010979         0.020282        0.002789   \n",
       "4         0.131177      0.019999         0.018459        0.001610   \n",
       "..             ...           ...              ...             ...   \n",
       "400       0.077087      0.003097         0.007812        0.002304   \n",
       "401       0.071896      0.001958         0.011937        0.002542   \n",
       "402       0.063945      0.002106         0.009393        0.001385   \n",
       "403       0.067480      0.003774         0.009203        0.003207   \n",
       "404       0.069842      0.004061         0.012205        0.003079   \n",
       "\n",
       "    param_estimator__colsample_bytree param_estimator__gamma  \\\n",
       "0                                 0.6                    0.5   \n",
       "1                                 0.6                    0.5   \n",
       "2                                 0.6                    0.5   \n",
       "3                                 0.6                    0.5   \n",
       "4                                 0.6                    0.5   \n",
       "..                                ...                    ...   \n",
       "400                               1.0                      5   \n",
       "401                               1.0                      5   \n",
       "402                               1.0                      5   \n",
       "403                               1.0                      5   \n",
       "404                               1.0                      5   \n",
       "\n",
       "    param_estimator__max_depth param_estimator__min_child_weight  \\\n",
       "0                            3                                 1   \n",
       "1                            3                                 1   \n",
       "2                            3                                 1   \n",
       "3                            3                                 5   \n",
       "4                            3                                 5   \n",
       "..                         ...                               ...   \n",
       "400                          5                                 5   \n",
       "401                          5                                 5   \n",
       "402                          5                                10   \n",
       "403                          5                                10   \n",
       "404                          5                                10   \n",
       "\n",
       "    param_estimator__subsample  \\\n",
       "0                          0.6   \n",
       "1                          0.8   \n",
       "2                          1.0   \n",
       "3                          0.6   \n",
       "4                          0.8   \n",
       "..                         ...   \n",
       "400                        0.8   \n",
       "401                        1.0   \n",
       "402                        0.6   \n",
       "403                        0.8   \n",
       "404                        1.0   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "0    {'estimator__colsample_bytree': 0.6, 'estimato...           0.790210   \n",
       "1    {'estimator__colsample_bytree': 0.6, 'estimato...           0.783217   \n",
       "2    {'estimator__colsample_bytree': 0.6, 'estimato...           0.783217   \n",
       "3    {'estimator__colsample_bytree': 0.6, 'estimato...           0.783217   \n",
       "4    {'estimator__colsample_bytree': 0.6, 'estimato...           0.776224   \n",
       "..                                                 ...                ...   \n",
       "400  {'estimator__colsample_bytree': 1.0, 'estimato...           0.776224   \n",
       "401  {'estimator__colsample_bytree': 1.0, 'estimato...           0.783217   \n",
       "402  {'estimator__colsample_bytree': 1.0, 'estimato...           0.776224   \n",
       "403  {'estimator__colsample_bytree': 1.0, 'estimato...           0.783217   \n",
       "404  {'estimator__colsample_bytree': 1.0, 'estimato...           0.776224   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0             0.825175           0.802817           0.823944   \n",
       "1             0.832168           0.795775           0.809859   \n",
       "2             0.832168           0.802817           0.823944   \n",
       "3             0.790210           0.795775           0.838028   \n",
       "4             0.811189           0.795775           0.845070   \n",
       "..                 ...                ...                ...   \n",
       "400           0.797203           0.774648           0.830986   \n",
       "401           0.804196           0.809859           0.852113   \n",
       "402           0.783217           0.774648           0.816901   \n",
       "403           0.797203           0.802817           0.823944   \n",
       "404           0.811189           0.795775           0.823944   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0             0.823944         0.813218        0.014217              116  \n",
       "1             0.845070         0.813218        0.022757              116  \n",
       "2             0.830986         0.814626        0.018911               95  \n",
       "3             0.809859         0.803418        0.019392              236  \n",
       "4             0.823944         0.810440        0.023529              148  \n",
       "..                 ...              ...             ...              ...  \n",
       "400           0.830986         0.802009        0.024964              257  \n",
       "401           0.830986         0.816074        0.023582               81  \n",
       "402           0.781690         0.786536        0.015519              396  \n",
       "403           0.809859         0.803408        0.013490              240  \n",
       "404           0.816901         0.804806        0.017040              222  \n",
       "\n",
       "[405 rows x 18 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Mejores hiperparámetros: \"+str(model.best_params_))\n",
    "print(\"Mejor Score: \"+str(model.best_score_)+'\\n')\n",
    "\n",
    "scores = pd.DataFrame(model.cv_results_)\n",
    "scores\n",
    "#'estimator__criterion': 'gini', 'estimator__max_depth': 8, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85       110\n",
      "           1       0.79      0.70      0.74        69\n",
      "\n",
      "    accuracy                           0.81       179\n",
      "   macro avg       0.80      0.79      0.79       179\n",
      "weighted avg       0.81      0.81      0.81       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_test)\n",
    "report = classification_report(y_test,prediction)\n",
    "print(\"Reporte de Clasificación:\")\n",
    "print(report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B.-Probamos modelos teniendo en cuenta lo sugerido por Gridsearch.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =complete_pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = complete_pipeline.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[103   7]\n",
      " [ 21  48]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test,prediction)\n",
    "print(\"Matriz de confusión:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88       110\n",
      "           1       0.87      0.70      0.77        69\n",
      "\n",
      "    accuracy                           0.84       179\n",
      "   macro avg       0.85      0.82      0.83       179\n",
      "weighted avg       0.85      0.84      0.84       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "report = classification_report(y_test,prediction)\n",
    "print(\"Reporte de Clasificación:\")\n",
    "print(report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C.-Elegido el modelo procedemos a entrenarlo con el dataset completo de Train para enviar la predicción sobre los datos de test a Kaggle en formato .csv.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =complete_pipeline.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_completo = data_test[['Pclass', 'Sex', 'Age','Fare','Embarked','0','SibSp']]\n",
    "prediction['PassengerID'] = data_test['PassengerId']\n",
    "prediction['Survived'] = complete_pipeline.predict(x_test_completo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived\n",
       "PassengerID          \n",
       "892                 0\n",
       "893                 1\n",
       "894                 0\n",
       "895                 0\n",
       "896                 1\n",
       "...               ...\n",
       "1305                0\n",
       "1306                1\n",
       "1307                0\n",
       "1308                0\n",
       "1309                0\n",
       "\n",
       "[418 rows x 1 columns]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.set_index('PassengerID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.to_csv(path_or_buf='resultados/SVC2.csv' , index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nPara guardar modelos con pickle\\npickle.dump(model, open('model.pkl', 'wb'))\\npickled_model = pickle.load(open('model.pkl', 'rb'))\\npickled_model.predict(X_test)\\n\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Para guardar modelos con pickle\n",
    "pickle.dump(model, open('model.pkl', 'wb'))\n",
    "pickled_model = pickle.load(open('model.pkl', 'rb'))\n",
    "pickled_model.predict(X_test)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b07fabb7e2ad75e61ea8af102191c1dc28df6d890ab8cb8f50853acc9feadfe4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
